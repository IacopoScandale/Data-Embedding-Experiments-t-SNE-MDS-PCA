{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EXERCISE: t-SNE**\n",
    "\n",
    "_**NOTE: The 3 best solutions will get +1 point to the final grade!**_\n",
    "\n",
    "We are now 2/3 through the ML course -- it's time to prove yourself a worthy ML practitioner! ðŸ¤“\n",
    "\n",
    "Your task is to fill in this Section. In particular:\n",
    "\n",
    "- Use markdown and code cells, as if you are writing this part of the notebook for your own students!\n",
    "- You can use Scikit-learn's implementation of t-SNE, your own, or whatever you prefer.\n",
    "\n",
    "The Section should include _at least_ the following experiments:\n",
    "\n",
    "- Embed the small digit data into 2D using t-SNE.\n",
    "- Embed the small digit data into 3D using t-SNE.\n",
    "- Comment on the differences you observe between the two plots.\n",
    "- Comment on the differences you observe with PCA and MDS embeddings in the same target space.\n",
    "- Embed a _larger_ dataset into 2D using t-SNE, e.g. MNIST, or character emojis, or pokemon images... you choose it!\n",
    "- Add whatever you think it's worth adding. If you think a t-SNE parameter needs further discussion, or some other aspect is worth discussing, feel free to do it!\n",
    "\n",
    "Send me your notebooks via email. Participation is not mandatory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Author:** *Iacopo Scandale*  \n",
    "> **Class:** *SMIA Machine Learning*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Imports and Reproducibility***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from plotly import express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "np.random.seed(23)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Scikit-Learn Small Digits***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's plot some elements of the small digit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits().data\n",
    "targets = load_digits().target\n",
    "\n",
    "\n",
    "# plot some images\n",
    "r,c = 3,10\n",
    "plt.figure(figsize=(c,r))\n",
    "for i in range(r*c):\n",
    "    plt.subplot(r,c,i+1)\n",
    "    plt.imshow(digits[i].reshape(8,8), cmap='gray')\n",
    "    # plt.title(f'target={targets[i]}', fontsize=8)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Visualization with t-SNE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot is quite clear: it allows us to distinguish clusters that form nearly precise groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "D_tsne_2d = TSNE(n_components=2).fit_transform(digits)\n",
    "D_tsne_3d = TSNE(n_components=3).fit_transform(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting t-SNE\n",
    "w,h = 900,400\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('2D Embedding', '3D Embedding'), specs=[[{'type': 'xy'}, {'type': 'scene'}]])\n",
    "\n",
    "fig.add_trace(px.scatter(x=D_tsne_2d[:,0], y=D_tsne_2d[:,1], color=targets).data[0], row=1,col=1)\n",
    "fig.add_trace(px.scatter_3d(x=D_tsne_3d[:,0], y=D_tsne_3d[:,1], z=D_tsne_3d[:,2], color=targets).data[0], row=1,col=2)\n",
    "\n",
    "fig.update_layout(title='Small digits t-SNE Embedding', \n",
    "                  title_font_size=24, \n",
    "                  width=w, height=h,\n",
    "                  coloraxis_colorbar=dict(tickmode='linear')\n",
    "                  )\n",
    "                  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h = 1200,600\n",
    "\n",
    "fig = px.scatter_3d(x=D_tsne_3d[:,0], y=D_tsne_3d[:,1], z=D_tsne_3d[:,2], \n",
    "                            text=[str(target) for target in targets])\n",
    "\n",
    "fig.update_traces(marker=dict(size=0.1, opacity=0))\n",
    "\n",
    "fig.update_layout(title='3D Representation with Targets', \n",
    "                  title_font_size=24, \n",
    "                  width=w, height=h)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Visualization with MDS*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following plot, we observe clusters closely grouped together. The use of colors facilitates the distinction of each group, although their accuracy does not match that achieved by t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDS\n",
    "D_mds_2d = MDS(n_components=2,n_init=1).fit_transform(digits)\n",
    "D_mds_3d = MDS(n_components=3, n_init=1).fit_transform(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting MDS\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('2D Embedding', '3D Embedding'), specs=[[{'type': 'xy'}, {'type': 'scene'}]])\n",
    "\n",
    "fig.add_trace(px.scatter(x=D_mds_2d[:,0], y=D_mds_2d[:,1], color=targets).data[0], row=1,col=1)\n",
    "fig.add_trace(px.scatter_3d(x=D_mds_3d[:,0], y=D_mds_3d[:,1], z=D_mds_3d[:,2], color=targets).data[0], row=1,col=2)\n",
    "\n",
    "fig.update_layout(title='Small digits MDS Embedding', title_font_size=24, width=w, height=h)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Visualization with PCA*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA dimensionality reduction is very similar to MDS. Points in MDS and PCA are not as widely separated as those in t-SNE, but the clusters are fairly well grouped and visible. \n",
    "\n",
    "Particularly noticeable is a slight difference observed in the large plots in *All three methods together* section. While MDS shows all points contained within a spherical shape, PCA exhibits more irregularities. This is likely because PCA emphasizes any differing directions within each cluster, as somewhat evident in the shape of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "D_pca_2d = PCA(n_components=2).fit_transform(digits)\n",
    "D_pca_3d = PCA(n_components=3).fit_transform(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting PCA\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('2D Embedding', '3D Embedding'), specs=[[{'type': 'xy'}, {'type': 'scene'}]])\n",
    "\n",
    "fig.add_trace(px.scatter(x=D_pca_2d[:,0], y=D_pca_2d[:,1], color=targets).data[0], row=1,col=1)\n",
    "fig.add_trace(px.scatter_3d(x=D_pca_3d[:,0], y=D_pca_3d[:,1], z=D_pca_3d[:,2], color=targets).data[0], row=1,col=2)\n",
    "\n",
    "fig.update_layout(title='Small digits PCA Embedding', title_font_size=24, width=w, height=h)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *All three methods together*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 1000, 600\n",
    "\n",
    "# plotting t-SNE\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('2D Embedding', '3D Embedding'), specs=[[{'type': 'xy'}, {'type': 'scene'}]])\n",
    "\n",
    "fig.add_trace(px.scatter(x=D_tsne_2d[:,0], y=D_tsne_2d[:,1], color=targets).data[0], row=1,col=1)\n",
    "fig.add_trace(px.scatter_3d(x=D_tsne_3d[:,0], y=D_tsne_3d[:,1], z=D_tsne_3d[:,2], color=targets).data[0], row=1,col=2)\n",
    "\n",
    "fig.update_layout(title='Small digits t-SNE Embedding', title_font_size=24, width=w, height=h)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# plotting MDS\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('2D Embedding', '3D Embedding'), specs=[[{'type': 'xy'}, {'type': 'scene'}]])\n",
    "\n",
    "fig.add_trace(px.scatter(x=D_mds_2d[:,0], y=D_mds_2d[:,1], color=targets).data[0], row=1,col=1)\n",
    "fig.add_trace(px.scatter_3d(x=D_mds_3d[:,0], y=D_mds_3d[:,1], z=D_mds_3d[:,2], color=targets).data[0], row=1,col=2)\n",
    "\n",
    "fig.update_layout(title='Small digits MDS Embedding', title_font_size=24, width=w, height=h)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# plotting PCA\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('2D Embedding', '3D Embedding'), specs=[[{'type': 'xy'}, {'type': 'scene'}]])\n",
    "\n",
    "fig.add_trace(px.scatter(x=D_pca_2d[:,0], y=D_pca_2d[:,1], color=targets).data[0], row=1,col=1)\n",
    "fig.add_trace(px.scatter_3d(x=D_pca_3d[:,0], y=D_pca_3d[:,1], z=D_pca_3d[:,2], color=targets).data[0], row=1,col=2)\n",
    "\n",
    "fig.update_layout(title='Small digits PCA Embedding', title_font_size=24, width=w, height=h)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Torchvision Fashion-Minst***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_dataset = datasets.FashionMNIST(\n",
    "    root='./',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.2868,), (0.3524,))\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some images\n",
    "classes = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
    "\n",
    "r,c = 3,10\n",
    "plt.figure(figsize=(c,r+0.5))\n",
    "for i in range(r*c):\n",
    "    plt.subplot(r,c,i+1)\n",
    "    plt.imshow(fm_dataset.data[i], cmap='gray')\n",
    "    plt.title(classes[int(fm_dataset.targets[i])],fontsize=8)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualization with t-SNE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to reshape our dataset into items, where each image has an unidimensional array of pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = fm_dataset.data.reshape(10000,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize our 2D and 3D t-SNE embeddings using standard scikit-learn's `sklearn.manifold.TSNE`, only using the `alpha` parameter for faster cell execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_tsne_2d = TSNE(n_components=2,\n",
    "                 # early_exaggeration=250,\n",
    "                 # perplexity=50,\n",
    "                 angle=0.95,\n",
    "                 ).fit_transform(items)\n",
    "\n",
    "F_tsne_3d = TSNE(n_components=3,\n",
    "                 # early_exaggeration=250,\n",
    "                 # perplexity=50,\n",
    "                 angle=0.95,\n",
    "                 ).fit_transform(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting t-SNE\n",
    "w,h = 1100,700\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('2D Embedding', '3D Embedding'), specs=[[{'type': 'xy'}, {'type': 'scene'}]])\n",
    "\n",
    "fig.add_trace(px.scatter(x=F_tsne_2d[:,0], y=F_tsne_2d[:,1], \n",
    "                         color=fm_dataset.targets, \n",
    "                         hover_name=[classes[i] for i in fm_dataset.targets]).data[0], \n",
    "                         row=1,col=1)\n",
    "fig.add_trace(px.scatter_3d(x=F_tsne_3d[:,0], y=F_tsne_3d[:,1], z=F_tsne_3d[:,2], \n",
    "                            color=fm_dataset.targets, \n",
    "                            hover_name=[classes[i] for i in fm_dataset.targets]).data[0], \n",
    "                            row=1,col=2)\n",
    "\n",
    "\n",
    "fig.update_layout(title='FascionMINST t-SNE Embedding', title_font_size=24, width=w, height=h)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Replicating some t-SNE experiments* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the t-SNE lesson slide, teacher suggested this site: https://distill.pub/2016/misread-tsne/ where are explained some behavior of representation with different parameters. \n",
    "\n",
    "In the site there are two easy examples of t-SNE:\n",
    "1. different perplexities  \n",
    "        ![Different Perplexities](perplexities.png)\n",
    "\n",
    "2. different steps (i.e. `n_iter`)  \n",
    "        ![Different Steps](steps.png)\n",
    "\n",
    "Taking inspiration from these two pictures, let's apply similar parameter values to the FashionMNIST dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *1. different perplexity values* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = [2, 5, 30, 50, 100]\n",
    "step = 500\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, \n",
    "    cols=5, \n",
    "    subplot_titles=[f\"{perplexity=}\" for perplexity in perplexities],\n",
    "    specs=[[{\"type\":\"xy\"} for _ in range(len(perplexities))],[{\"type\":\"scene\"} for _ in range(len(perplexities))]]\n",
    ")\n",
    "# first row of 2d plots\n",
    "for i in tqdm(range(len(perplexities)), desc=\"2d t-SNE and plots\"):\n",
    "    F_tsne_2d = TSNE(n_components=2, perplexity=perplexities[i], angle=0.95, max_iter=step).fit_transform(items)\n",
    "\n",
    "    fig.add_trace(\n",
    "        px.scatter(\n",
    "            x=F_tsne_2d[:,0], \n",
    "            y=F_tsne_2d[:,1], \n",
    "            color=fm_dataset.targets, \n",
    "            hover_name=[classes[i] for i in fm_dataset.targets]\n",
    "        ).data[0], \n",
    "        row=1,col=i+1\n",
    "    )\n",
    "# second row of 3d plots\n",
    "for i in tqdm(range(len(perplexities)), desc=\"3d t-SNE and plots\"):\n",
    "    F_tsne_3d = TSNE(n_components=3, perplexity=perplexities[i], angle=0.95, max_iter=step).fit_transform(items)\n",
    "\n",
    "    fig.add_trace(px.scatter_3d(\n",
    "        x=F_tsne_3d[:,0], \n",
    "        y=F_tsne_3d[:,1],\n",
    "        z=F_tsne_3d[:,2],\n",
    "        color=fm_dataset.targets, \n",
    "        hover_name=[classes[i] for i in fm_dataset.targets]).data[0], \n",
    "    row=2,col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_layout(width=1400, height=700)\n",
    "fig.show()\n",
    "# about 7 minutes run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this result with the picture below, we can observe how low perplexity leads to a more spherical shape. As its value increases, data points begin to separate into different clusters, which become clearer with higher perplexity values. In this example, we do not observe cluster fragmentation at high perplexity values. Furthermore, when experimenting with a high perplexity value (e.g., 1000), this phenomenon does not occur.\n",
    "\n",
    "![perp](perplexities.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *2. different step values* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [250,300,350,450,1000]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, \n",
    "    cols=5, \n",
    "    subplot_titles=[f\"{step=}\" for step in steps],\n",
    "    specs=[[{\"type\":\"xy\"} for _ in range(len(steps))],[{\"type\":\"scene\"} for _ in range(len(steps))]]\n",
    "    )\n",
    "\n",
    "# first row of 2d plots\n",
    "for i in tqdm(range(len(steps)), desc=\"2d t-SNE and plots\"):\n",
    "    F_tsne_2d = TSNE(n_components=2, max_iter=steps[i], angle=0.95).fit_transform(items)\n",
    "\n",
    "    fig.add_trace(\n",
    "        px.scatter(\n",
    "            x=F_tsne_2d[:,0], \n",
    "            y=F_tsne_2d[:,1], \n",
    "            color=fm_dataset.targets, \n",
    "            hover_name=[classes[i] for i in fm_dataset.targets]\n",
    "        ).data[0], \n",
    "        row=1,\n",
    "        col=i+1\n",
    "    )\n",
    "# second row of 3d plots\n",
    "for i in tqdm(range(len(steps)), desc=\"3d t-SNE and plots\"):\n",
    "    F_tsne_3d = TSNE(n_components=3, n_iter=steps[i], angle=0.95).fit_transform(items)\n",
    "\n",
    "    fig.add_trace(\n",
    "        px.scatter_3d(\n",
    "            x=F_tsne_3d[:,0], \n",
    "            y=F_tsne_3d[:,1],\n",
    "            z=F_tsne_3d[:,2],\n",
    "            color=fm_dataset.targets, \n",
    "            hover_name=[classes[i] for i in fm_dataset.targets]\n",
    "        ).data[0], \n",
    "        row=2,\n",
    "        col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_layout(width=1400, height=700)\n",
    "fig.show()\n",
    "# about 3 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately it is not possible to use steps values below 250 for scikit-learn t-SNE. We can clearly see that 250 steps are not sufficient. In fact, especially in the 3d version we see that all points are flattened and mixed together. With higher values we arrive to out previous solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***PCA and t-SNE experiment***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I'd like to share an idea I've been pondering while waiting for the previous code cells to execute, which can take several minutes. What if we utilize PCA to reduce dimensionality first and then apply t-SNE for visualization?\n",
    "\n",
    "Clearly first we want to determine an optimal number of principal components that effectively represent our dataset. Let's begin by employing PCA with all dimensions and identifying the suitable number.\n",
    "\n",
    "We'll repurpose code from the PCA lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_full = PCA(n_components=784)\n",
    "_ = pca_full.fit(items)\n",
    "\n",
    "plt.figure(figsize=(5,2))\n",
    "plt.plot(pca_full.singular_values_, zorder=2, color='skyblue', linewidth=4)\n",
    "plt.grid('on')\n",
    "plt.xlabel('Singular values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably 50 components are necessary for describing the dataset. Let's use only 6!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing to 6 dimensions instead of 784 \n",
    "X_pca = PCA(n_components=6).fit_transform(items)\n",
    "\n",
    "X_pca_tsne_2d = TSNE(n_components=2).fit_transform(X_pca)\n",
    "X_pca_tsne_3d = TSNE(n_components=3).fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my machine, it takes 1.53m compared to about 2.3m from the full t-SNE. While the gain isn't significant, let's see if it works at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting t-SNE\n",
    "w,h = 900,500\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('2D Embedding', '3D Embedding'), specs=[[{'type': 'xy'}, {'type': 'scene'}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    px.scatter(\n",
    "        x=X_pca_tsne_2d[:,0], \n",
    "        y=X_pca_tsne_2d[:,1], \n",
    "        color=fm_dataset.targets,\n",
    "        hover_name=[classes[i] for i in fm_dataset.targets]\n",
    "    ).data[0], \n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    px.scatter_3d(\n",
    "        x=X_pca_tsne_3d[:,0], \n",
    "        y=X_pca_tsne_3d[:,1], \n",
    "        z=X_pca_tsne_3d[:,2], \n",
    "        color=fm_dataset.targets,\n",
    "        hover_name=[classes[i] for i in fm_dataset.targets]\n",
    "    ).data[0], \n",
    "    row=1,\n",
    "    col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(title='Torcvision FashionMINST PCA and t-SNE Embedding', \n",
    "                  title_font_size=24, \n",
    "                  width=w, height=h,\n",
    "                  coloraxis_colorbar=dict(tickmode='linear')\n",
    "                  )\n",
    "                  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems good. Is it very different to applying only PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_2d = PCA(n_components=2).fit_transform(items)\n",
    "X_pca_3d = PCA(n_components=3).fit_transform(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting t-SNE\n",
    "w,h = 900,400\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('2D Embedding', '3D Embedding'), specs=[[{'type': 'xy'}, {'type': 'scene'}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    px.scatter(\n",
    "        x=X_pca_2d[:,0], \n",
    "        y=X_pca_2d[:,1], \n",
    "        color=fm_dataset.targets,\n",
    "        hover_name=[classes[i] for i in fm_dataset.targets]\n",
    "    ).data[0], \n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    px.scatter_3d(\n",
    "        x=X_pca_3d[:,0], \n",
    "        y=X_pca_3d[:,1], \n",
    "        z=X_pca_3d[:,2], \n",
    "        color=fm_dataset.targets,\n",
    "        hover_name=[classes[i] for i in fm_dataset.targets]\n",
    "    ).data[0], \n",
    "    row=1,\n",
    "    col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(title='Torcvision FashionMINST PCA Dimensionality Reduction', \n",
    "                  title_font_size=24, \n",
    "                  width=w, height=h,\n",
    "                  coloraxis_colorbar=dict(tickmode='linear')\n",
    "                  )\n",
    "                  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes, it is "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
